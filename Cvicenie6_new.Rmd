---
title: "Cvičenie 6 - Modelovanie volatility - GARCH a kamaráti"
output:
  html_document: 
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: no
    number_sections: yes
    theme: flatly
    highlight: zenburn
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Potrebne knižnice pre cvičenie 6
```{r include=FALSE}
library(fGarch)
library(astsa)
library(quantmod)
library(urca)
library(ggplot2)
library(ggfortify)
library(forecast)
```

```{r eval=FALSE}
library(fGarch)
library(astsa)
library(quantmod)
library(urca)
library(ggplot2)
library(ggfortify)
library(forecast)
```

# Dáta 1 - ceny akcie Apple
V prvej časti budeme, tak ako na prednáške, pracovať s logaritmickými výnosmi pre ceny akcií. 
Konkrétne sa pozrieme na výnosy akcie `AAPL` (Apple):
```{r}
getSymbols("AAPL",
           from = "2016-01-01",
           to = "2021-01-01",
           auto.assign = TRUE)
```

Budeme pracovať s týždennými dátami.
```{r}
AAPL.tyzden <- to.weekly(AAPL)
head(AAPL.tyzden)
```

Transformácia cien na logaritmické výnosy:
```{r}
ceny <- AAPL.tyzden$AAPL.Adjusted
vynosy <- diff(log(ceny))
vynosy <- vynosy[-1]
```

Vykreslenie dát
```{r}
chartSeries(vynosy, theme=chartTheme('white',up.col="#009E73"))
```

Skontrolujeme dáta, či v nich náhodou nie je jednotkový koreň:
```{r}
autoplot(vynosy)+
  geom_hline(yintercept = 0, color = "green")+
  geom_hline(yintercept = mean(vynosy), color = "orange")
```

Obe čiary sú dosť pri sebe, použijeme type = "none"
```{r}
summary(ur.df(vynosy, lags = 5, selectlags = "BIC", type = "none"))
```
Hypotézu o jednotkovom koreni zamietame, takže dáta nebude treba differencovať.

Vykreslíme si ACF a PACF pre naše dáta 
```{r}
acf2(vynosy)
```

Vidíme, že podľa ACF aj PACF by sme dáta mohli modelovať ako konštanta + biely šum.
```{r}
vynosy.00 <- capture.output(sarima(vynosy,0,0,0))
vynosy.00 <- sarima(vynosy,0,0,0, details = FALSE)
vynosy.00
```

Porovnáme si ACF pre rezídua a pre ich druhé mocniny:
```{r}
acf1(vynosy.00$fit$residuals)
acf1(vynosy.00$fit$residuals^2)
```

Vidíme, že hoci samotné rezídua nevyzerajú byť korelované, ich druhé mocniny sú. Takúto vlastnosť ale biely šum nemá. Preto budeme dáta modelovať ako GARCH(p,q).

## ARCH(p)

Najskôr budeme dáta modelovať iba ako ARCH(p) proces. Začneme základným ARCH(1) procesom. Použijeme funkciu `garchFit` z knižnice `fGarch.`:

* `~garch(1,0)` - predstavuje formulu, všeobecne v tvare `~arma(p,q)+garch(p,q)`
* `data` - naše dáta
* `trace` - ak chceme vypísať konvergenciu, atď... (FALSE ak nechceme)
```{r}
vynosy.10 <- garchFit(~garch(1,0), data = vynosy, trace = FALSE)
vynosy.10
```

Z výstupu môžeme vidieť odhady pre jednotlivé parametre:

* `mu` - konštanta v rovnici pre strednú hodnotu
* `omega` - konštanta v rovnici pre disperziu
* `alpha1` - koeficient pri $u_{t-1}^2$

Spolu s odhadmi sú dané aj štandardné odchýlky a hodnota testovej štatistiky (H0 daný koeficient je nulový) spolu s p-value.

Všetky tri koeficienty sú signifikantné.

Pozrieme sa ešte na zhodnotenie rezíduí. Dobrý model bude taký, kde nezostane žiadna autokorelácia v rezíduách ani v ich druhým mocninách, a zároveň Hypotéza o homoskedasticite sa nebude zamietať. K týmto hodnotám pristúpime cez funckiu `summary`, ktorá nám ponúka aj hodnotu Informačných kritérií pre daný model. K tým budeme ale pristupovať neskôr.
```{r}
summary(vynosy.10)
```
Vidíme, že stále ostáva istá autokorelácia medzi druhými mocninami rezíduí, aj keď samotné rezíduá nie sú korelované. Rovnako sa zamieta aj LM Arch test, teda zamietame hypotézu o homoskedasticite (konštantnosti disperzie v rezíduach).

Skúsime teda zvýšiť rád ARCH procesu. ARCH(2):
```{r}
vynosy.20 <- garchFit(~garch(2,0), data = vynosy, trace = FALSE)
vynosy.20

summary(vynosy.20)
```
Vidíme, že koeficient `alpha2` vyšiel nesignifikantný, zároveň sa však zachovali nedostatky rezíduí z ARCH(1) procesu (v niektorých prípadoch dokonca horšie p hodnoty).

ARCH(3)
```{r}
vynosy.30 <- garchFit(~garch(3,0), data = vynosy, trace = FALSE)
vynosy.30

summary(vynosy.30)
```

Opäť máme nesignifikantné koeficienty, no druhé mocniny rezíduí sú už bez výraznej autokorelácie, LM Arch test sa nezamietol, teda môžeme predpokladať konštatnú disperziu v rezíduách. Teda rezíduá môžeme považovať za biely šum.

## GARCH(p,q)
ARCH(3) proces vyšiel ako vhodný model pre naše dáta, avšak vyšli nám v ňom dva koeficienty nesignifikantné. Preto sa pozrieme aj na zovšeobecnený ARCH proces, GARCH. Skúsime začať základným, ktorý sa vo veľa prípadoch ukazuje ako dostatočný na modelovanie volatility, GARCH(1,1)
```{r}
vynosy.11 <- garchFit(~garch(1,1), data = vynosy, trace = FALSE)
vynosy.11

summary(vynosy.11)
```
Všetky koeficienty vyšli signifikatné, aj keď koeficient `beta1` (koeficient pri $\sigma_{t-1}^2$) vyšiel dosť nahrane. Čo však je možné pozorovať je, že testy nám nezamietli ani nulovú koreláciu medzi rezíduami, ani pre ich druhé mocniny, ani LM Arch test pre homoskedasticitu v rezíduách. Teda, tak ako ARCH(3), aj GARCH(1,1) je pre naše dáta dobrým modelom.

Na ukážku ešte vyskúšame GARCH proces vyššieho rádu napríklad GARCH(1,2), teda jeden krát člen $u_{t-1}^2$ a dva krát predošle hodnoty $\sigma^2$.
```{r}
vynosy.12 <- garchFit(~garch(1,2), data = vynosy, trace = FALSE)
vynosy.12

summary(vynosy.12)
```

Vhodný model pre naše dáta môžeme zvoliť napríklad podľa informačných kritérií, ku ktorým vieme pristúpiť nasledovne.
```{r}
vynosy.30@fit$ics # ARCH(3)
vynosy.11@fit$ics # GARCH(1,1)
vynosy.12@fit$ics # GARCH(1,2)
```

Vidíme, že spomedzi troch modelov, ktoré boli pre naše dáta vyhovujúce, má najmenšie hodnoty informačných kritérií práve GARCH(1,1). Ten ďalej použijeme aj na predikcie z modelu.

## Predikcie
Podobne ako pri Holt-Wintersovej metóde, predikcie budeme robiť pomocou funkcie `predict`
```{r}
vynosy.pred11 <- predict(vynosy.11, n.ahead = 50, plot = TRUE)
```

Keďže dáta modelujeme ako konštantu plus biely šum, predikcie do budúcnosti bude tiež iba samotná konštanta. Na druhú stranu, môžeme vidieť, že podmienená postupne narastá a konverguje k nepodmienenej disperzií časového radu. Prejaví sa to tak, že sa nám postupne rozšírujú intervaly spoľahlivosti.

# Data 2 - výmenné kurzy PLN/EUR

Načítanie a úprava dáta na logaritmické výnosy. Dáta sú za obdobie 3 rokov, voľne dostupné na https://www.ecb.europa.eu/stats/policy_and_exchange_rates/euro_reference_exchange_rates/html/index.en.html
```{r}
data_ex <- read.table("https://alex-babis.github.io/Casove_Rady_2022/EX_data.txt",
                      header = TRUE, sep = ",")
```

Finálne dáta budú predstavovať stĺpec 7:
```{r}
vynosy <- as.ts(data_ex[,7])
```

Vykreslíme si dáta a skontrolujeme, či sa v nich nenachádza jednotkový koreň
```{r}
autoplot(vynosy)+
  geom_hline(yintercept = 0, color = "green")+
  geom_hline(yintercept = mean(vynosy), color = "orange")
```

Obe čiary sú blízko pri sebe, teda použijeme `type = "none"`:
```{r}
summary(ur.df(vynosy, lags = 5, selectlags = "BIC", type = "none"))
```

Test zamieta hypotézu o jednotkovom koreni, teda dáta nebude treba diferencovať.

Ako už z obrázku vidieť, dáta pozostávajú z období väčšej a menšej volatility.

Pozrieme sa najskôr na ACF a PACF pre naše dáta
```{r}
acf2(vynosy)
sarima(vynosy, 0, 0, 0)
```

V tomto prípade sa samotný časový rad nedá považovať za biely šum posunutý o konštantu. Vidíme v ACF aj PACF autokorelácie mimo intervalov spolahlivosti. Rovnako nevychádzajú ani Ljung-Boxové testy. 

## ARMA 
Poďme ako prvé skúsiť nájsť obyčajný ARMA model pre naše dáta. Podľa ACF a PACF by sa mohlo zdať, že dobrý model by mohol byť AR(2), MA(3), MA(4) alebo nejaký zmiešaný model

```{r}
vynosy.ar2 <- capture.output(sarima(vynosy, 2, 0 ,0))
vynosy.ar3 <- capture.output(sarima(vynosy, 3, 0 ,0))
vynosy.ma2 <- capture.output(sarima(vynosy, 0, 0 ,2))
vynosy.ma3 <- capture.output(sarima(vynosy, 0, 0 ,3))
vynosy.31 <- capture.output(sarima(vynosy, 3, 0 ,1))
```

Vidíme, že jediný vyhovujúci z tých, ktoré sme vyskúšali je ARMA(3,1). Poďme sa pozrieť, ako sú natom rezíduá a ich druhé mocniny.
```{r}
vynosy.31 <- sarima(vynosy, 3, 0 ,1,details = FALSE)
acf1(vynosy.31$fit$residuals)
acf1(vynosy.31$fit$residuals^2)
```

Vidíme, že zatiaľ, čo autokorelačná funkcia pre rezíduá pripomína tú pre biely šum, druhé mocniny rezíduí sú evidentne korelované, a teda o biely šum nejde. Bohužial pre prípad, keď sa nejedná o čisto GARCH model, nie je dobré najskôr samostantne určiť rád členov ARMA procesu a potom dourčiť rád GARCH procesu (ak nejde o čisto AR proces), to z dôvodu, že tieto dve rovnice sú navzájom prepojené, keďže v oboch by vystupovali nejaké rovnaké predošlé hodnoty $u_{t-s}$.

## GARCH

Vyskúšame najskôr čisto GARCH(1,1)
```{r}
vynosy.00.11 <- garchFit(~ garch(1,1), data = vynosy, trace = FALSE)
vynosy.00.11 
summary(vynosy.00.11)
```

Vidíme, že testy pre druhé mocniny rezíduí ako aj LM Arch test vyšli dobre. Parametre GARCH procesu vyšli signifikatné (až na konštantu z rovnice pre strednú hodnotu). Čo však nevyšlo dobre, sú Ljung-Boxové testy o nezávislosti rezíduí.

Skúsime preto použiť zmiešany ARMA+GARCH proces. Zoberme opäť GARCH(1,1) a AR(1)

```{r}
vynosy.10.11 <- garchFit(~ arma(1,0)+garch(1,1), data = vynosy, trace = FALSE)
vynosy.10.11 
summary(vynosy.10.11)
```

AR člen vyšiel nesignifikatný, testy o nekorelovanosti rezíduí boli opäť zamietnuté. Skúsme vyšší AR rad.
AR(2)

```{r}
vynosy.20.11 <- garchFit(~ arma(2,0)+garch(1,1), data = vynosy, trace = FALSE)
vynosy.20.11 
summary(vynosy.20.11)
```

V tomto prípade nám síce opäť vyšli nesignifikantné koeficienty, avšak tento krát sa testy pre nekorelovanosť rezíduí nezamietli. Ak si ich porovname s testami pre čisto s AR(2) proces, tak vidíme, že zatiaľ čo samotný AR(2) proces bol nevyhovujúci ako model, AR(2)+GARCH(1,1) je už vyhovujúcim modelom.
```{r}
vynosy.ar2 <- capture.output(sarima(vynosy,2,0,0))
```

Skúsme ešte porovnať AR(2)+GARCH(1,1) s ARMA(3,1)+GARCH(1,1) (keďže ARMA(3,1) nám vyšiel ako možný kandidát na model pre dáta, zlyhal na korelovanosti druhých mocnín rezíduí)

```{r}
vynosy.31.11 <- garchFit(~ arma(3,1)+garch(1,1), data = vynosy, trace = FALSE)
vynosy.31.11 
summary(vynosy.31.11)
```

Môžeme porovnať ich informačné kritéria
```{r}
vynosy.20.11@fit$ics # AR(2)+GARCH(1,1)
vynosy.31.11@fit$ics # ARMA(3,1)+GARCH(1,1)
```

Podľa informačných kritérií, pridanie ďaľších dvoch členov v ARMA procese neprinieslo výrazne zlepšie v fittovaní dát (informačné kritéria skoro rovnaké). Z tohto dôvodu je lepšie odhadovať rád ARMA časti a GARCH časti dokopy.

## Predikcie
Rovnako ako pri výnosoch akcií spravíme predikcie pre výnosy výmenných kurzov 12 dní dopredu. Použijeme AR(2)+GARCH(1,1) proces.
```{r warning=FALSE}
vynosy.pred.20.11 <- predict(vynosy.20.11, n.ahead = 12, plot = TRUE, nx = 70)
```

# Alternatívny balíček pre GARCH a kamaráti
```{r warning=FALSE}
library(rugarch)
```

Odhadneme rovnaký model ale pomocou iného balíka, ktorý ponúka väčšiu flexibilitu.

Najskôr zadefinujeme model:
```{r}
spec.20.11 <- ugarchspec( variance.model = list(model = "sGARCH",
                                          garchOrder  = c(1,1),
                                          submodel = NULL),
                      mean.model = list(armaOrder = c(2,0),
                                        include.mean = TRUE,
                                        archm = FALSE),
                      distribution.model = "norm")
```

Fittovanie modelu:
```{r}
fit.20.11 <- ugarchfit(spec = spec.20.11, data = vynosy)

fit.20.11
```


Predikcie modelu:
```{r}
pred.20.11 <- ugarchforecast(fit.20.11, data = NULL, n.ahead = 12)

pred.20.11
```


# Výpočet VaR a testovanie VaR

Value at risk predstavuje mieru rizika, ktorá nám hovorí aké najväčšie straty s pravdepodonosťou $1 - \alpha$, kde $\alpha$
je nejaká hladina pravdepodobnosti,môžeme očakávať v nasledujúcom období (to si potom definujeme). Označme X hodnotu portfólia. Potom $VaR_{\alpha}$ je taká hodnota, pre ktorú platí, že
$$P(X \leq VaR_{\alpha})=\alpha$$
Teda, $VaR_{\alpha}$ predstavuje $1 - \alpha$ kvantil rozdelenia možných hodnôt X. Ak predpokladáme normálne rozdelenie pre naše dáta, tak to nie je nič iné ako $1 - \alpha$ kvantil normálneho rozdelenia.

## VaR pre Apple akciu
Data pre ceny akcie
```{r}
ceny <- AAPL.tyzden$AAPL.Adjusted
vynosy <- diff(log(ceny))
vynosy <- vynosy[-1]
```

Model použijeme GARCH(1,1). Budeme počítať VaR iteračne. Každý deň budeme fitovať GARCH(1,1) proces pre naše dáta a spravíme pridkciu volatility na ďalší deň. Odhadovať budeme vždy z posledných 50 pozorovaní.

Zadefinujeme si prázdny VaR vektor:
```{r, warning=FALSE}
N <- 50
var.aaple <- rep(0, length(vynosy) - N + 1)
for(i in 1:length(var.aaple))
{
  data.aapl <- vynosy[i:(i+N-1)]
  garch.aapl <- garchFit(~garch(1,1), data = data.aapl, trace = FALSE)
  aapl.pred <- predict(garch.aapl, n.ahead = 1, plot = FALSE)
  var.aaple[i] <- qnorm(0.05, mean = aapl.pred[1,1],sd = aapl.pred[1,3])
}
```

Vytvoríme z výsnosov aj VaR časové rady. VaR začína až od N+1 dňa.
```{r}
vynosy <- ts(vynosy)
var.aaple <- ts(var.aaple, start = N + 1)
```

Vykreslíme do jedného grafu
```{r}
pallete <-  c("#D55E00","black")
autoplot(vynosy, series = "Vynosy applu")+
  autolayer(var.aaple, series = "VaR 95%")+
  scale_colour_manual(values=pallete)+
  ggtitle("Porovanie vynosov a VaR na 5% hladine")
```

Vypočítame si % prekročení VaR
```{r}
pocet <- sum(vynosy[(N + 1):length(vynosy)] < var.aaple[-length(var.aaple)])
pocet
perc <- 100*pocet/length(var.aaple[-length(var.aaple)])
perc
```

Vidíme, že frekvencia prekorčení je  viac ako 5%, teda náš model nemusí byť úplne najvhodnejší na výpočet value at risk . Rovnako by ešte trebalo testovať, či sú jednotlivé prekročenia od seba nezávislé.

## Testovanie Value at risk 

### Kupiecov test
Chceme vedieť, či frekvencia prekročení je zhodná s predefinovanou hľadinou VAR. Ak sme správne odhadli VaR, potom by sa mali rovnať.
Definujme si funkciu $I(\alpha) = \sum_{t=0}^{n}I_{t}(\alpha)$, kde $I_{t}(\alpha)$ je rovné 1 ak $r_{t} < VaR_{t}(\alpha)$, 0 inak. Pozorovanú frekvenciu prekročení vieme potom spočítať ako $\hat{\alpha}=\frac{I(\alpha)}{n}.$ Ďalej predpokladáme, že prekročenia sú nezávislé z Alternativného rozdelenia s parametrom $\alpha$.Potom počet prekročení má Binomické rozdelenia. Myšlienka Kupiecovho testu:
$$H_{0}: \alpha = \hat{\alpha} \quad vs \quad H1: \alpha \neq \hat{\alpha}.$$ 
Ak platí nulová hypotéza potom likelihoodratio štatistika má hodnotu
$$LR_{uc}=2\ln((\frac{1-\hat{\alpha}}{1-\alpha})^{n-I(\alpha)}(\frac{\hat{\alpha}}{\alpha})^{I(\alpha)}) \sim \chi^{2}_{1}.$$

Testujte pomocou Kupiecovho testu prekročenia Value at Risk:
```{r eval = FALSE}
pocet <- ?
freq <- ?
celkovy.pocet <- ?

LRuc <- 2*log( ? )

pchisq(?, df = ?, lower.tail = FALSE)

```


```{r echo = FALSE}
pocet <- sum(vynosy[(N + 1):length(vynosy)] < var.aaple[-length(var.aaple)])
pocet
freq <- pocet/length(var.aaple[-length(var.aaple)])
freq
celkovy.pocet <- length(var.aaple[-length(var.aaple)])
celkovy.pocet


LRuc <- 2*log( ((1-freq)/(1-0.05))^(celkovy.pocet-pocet)*(freq/0.05)^pocet )

pchisq(LRuc, df = 1, lower.tail = FALSE)

```


## Christoffersen
Aj sériovo závislé prekročenia nám robia problém. Zhlukovanie prekročení môže spôsobiť, že dva dni po sebe budeme pozorovať straty, na ktoré nebudeme kapitálovo pripravení. Preto je dôležité aby platila nezávislosť prekročení. Majme proces prekročení $I_{t}$, ktorý môžeme modelovať ako Markovoský reťazec $\pi_{ij}=Pr(I_{t}(\alpha)=j \vert I_{t-1}(\alpha)=i)$. Nech $N_{ij}$ je počet pozorovaní v stave $j$ ak v predošlej perióde boli v stave $i$ a označme $N_{0}=N_{00}+N_{10}$, $N_{1}=N_{11}+N_{01}$. Ďalej označme odhad pravdepodobností prechodu zo stavov ako: $\pi_{01},\pi_{11}$, ktoré vieme spočítať nasledovne $\hat{\pi}_{01}=\frac{N_{01}}{N_{01}+N_{00}}$ a $\hat{\pi}_{11}=\frac{N_{11}}{N_{11}+N_{10}}$ respektívne. Hypotézu o nezávisloti vieme sformulovať ako
$$H_{0}: \pi_{01}=\pi_{11}=\pi \quad vs \quad H1: \pi_{01} \neq \pi_{11}.$$
Za platností nulovej hypotézy dostávame likelihood štatistiku:
$$LR_{ind}=-2\ln(  \frac{(1-\pi)^{N_{0}}\pi^{N_{1}}}{(1-\pi_{01})^{N_{00}}\pi_{01}^{N_{01}}(1-\pi_{11})^{N_{10}}\pi_{11}^{N_{11}}} ) \sim \chi^{2}_{1},$$ kde $\pi$ môžeme odhadnúť ako $\hat{\pi}=\frac{N_{01}+N_{11}}{N_{00}+N_{01}+N_{10}+N_{11}}$. 

```{r eval=FALSE}
prekrocenia <- (vynosy[(N + 1):length(vynosy)] < var.aaple[-length(var.aaple)])*1

# 2 x 0 za sebou
N00 <- sum( ? )
N01 <- sum( ? )
N10 <- sum( ? )
N11 <- sum( ? )


N0 <- ?
N1 <- ?


p01 <- ?
p11 <- ?
p <- ?


LRind <- -2*log( ? )

LRind


pchisq(?, df = ?, lower.tail = FALSE)
```

```{r echo=FALSE}
prekrocenia <- (vynosy[(N + 1):length(vynosy)] < var.aaple[-length(var.aaple)])*1

# 2 x 0 za sebou
N00 <- sum( (prekrocenia[-1] + prekrocenia[-length(prekrocenia)]) == 0)
N01 <- sum( (prekrocenia[-1] - prekrocenia[-length(prekrocenia)]) == -1)
N10 <- sum( (prekrocenia[-1] - prekrocenia[-length(prekrocenia)]) == 1)
N11 <- sum( (prekrocenia[-1] + prekrocenia[-length(prekrocenia)]) == 2)


N0 <- N00 + N10
N1 <- N11 + N01


p01 <- N01/(N01 + N00)
p11 <- N11/(N11 + N10)
p <- (N01+N11)/(N00 + N01 + N10 + N11)


LRind <- -2*log(  ((1-p)^N0*p^N1) / ( (1-p01)^N00*p01^N01*(1-p11)^N10*p11^N11 )   )

LRind


pchisq(LRind, df = 1, lower.tail = FALSE)
```


## Spojený test
Pre silnejší test vieme obe testy dokopy (teda testovať nezávislosť aj frekvenciu naraz), čím dostaneme novú testovú štatistiku, ktorá má ale rozdelenie $\chi^{2}_{2}$.

```{r eval=FALSE}
pchisq( ? , df = ? , lower.tail = FALSE)
```

```{r echo=FALSE}
pchisq(LRuc + LRind, df = 2, lower.tail = FALSE)
```

## Iné dynamiky volatility
### IGARCH process - Integrovaný GARCH
Môžeme vyjadriť rovnicu pre varianciu ako ARCH proces s nekonečným rádom
$$\sigma_{t}^{2}=\omega(1-\beta(L))^{-1} + \alpha(L)(1-\beta(L))^{-1}e_{t}^{2},$$
$$\sigma_{t}^{2}=\omega(1-\beta(L))^{-1} + \lambda(L)e_{t}^{2}$$
Môžeme si ďalej všimnúť, že podmienky stacionarity implikujú, že efekt minulých kvadratických inovácií na varianciu v čase $t$ klesá exponenciálne so zvyšujúcou sa dĺžkou lagu. Autori niektorých článkov detekovali, že polynóm  $\alpha(L) + \beta(L)$ má koreň blízky $1$. Toto inšpirovalo odvodenie IGARCH procesu. Ak preusporiadáme GARCH proces do formy $ARMA(m,p)$ v neznámej $e_{t}^{2}$
$$(1-\alpha(L)-\beta(L))e_{t}^{2}=\omega +(1-\beta(L))\nu_{t},$$
kde $m=max(p,q)$ a $\nu_{t}= e_{t}^{2}- \sigma_{t}^{2}$ je nezávislý so strednou hodnotou 1. Proces $\{\nu_{t} \}$ môžeme vnímať ako inovácie pre podmienenú varianciu. Ak má polynóm $1-\alpha(L)-\beta(L)$ má jednotkový koreň, potom hovoríme, že je integrovaný vo variancií. To taktiež znamená, že efekt druhých mocnín rezíduí má signifikantný vplyv na varianciu v každom čase. $IGARCH(p,q)$ môžeme zapísať ako
$$\phi(L)(1-L)e_{t}^{2}= \omega + (1-\beta(L))\nu_{t},$$
kde $\phi(L)=(1-\alpha(L)-\beta(L))(1-L)^{-1}$ je rádu $m-1$.

### FIGARCH proces - Zlomkovo integrovaný
Môžeme nahradiť rád diferencovania $1-L$ v IGARCH rovnici s operátorom zlomkového diferencovania $(1-L)^{d}$. $FIGARCH(p,d,q)$ vieme zapísať ako
$$\phi(L)(1-L)^{d}e_{t}^{2}=\omega+(1-\beta(L))\nu_{t},$$
kde opäť $\nu_{t}= e_{t}^{2}- \sigma_{t}^{2}$ a $0<d<1$. GARCH proces je stacionárny vo variancií, keoficienty ale klesajú exponenciálne, a IGARCH je proces s nekonečným vplyvom predošlých druhých mocnín rezíduí na súčasnú volatilitu, pre FIGARCH proces efekt predošlých inovácií klesá veľmi pomaly so zvyšujúcim sa lagom, teda niečo medzi GARCH a IGARCH procesom. 


### EGARCH proces
Exponenciálny  GARCH proces, $EGARCH(p,q)$,definovaný ako 
$$\ln(\sigma^{2}_{t})= \omega + \sum_{j=1}^{p}g_{j}(z_{t-j}) + \sum_{j=1}^{q}\beta_{j}\ln(\sigma^{2}_{t-j}),$$
s $g_{j}(z_{t-j}) = \alpha_{j}z_{t-j} + \psi_{j}(\vert z_{t-j}\vert -E[z_{t-j}]),$ pre $j=1,...,p$, nám umožnuje pracovať bez obmedzení na parametre, keďže volatilita je vždy kladná, $\sigma_{t}^{2}$. Parametre $\alpha_{j}$ pre $j=1,...,p$ nám dovoľujú zakomponovať asymetrickú informáciu na "šoky" v dynamike volatility .

### GJR-GARCH proces
Ďalší proces, ktorý nám dovoľuje zakomponovať asymetrickú informáciu, alebo pákový efekt, je Glosten, Jagannathan and Runkle GARCH proces (GJR-GARCH). V $GJR-GARCH$ procese, asymetrická informácia je zakomponovaná pomocou indikátorovej funkcie. Vo všeobecnosti vieme $GJR-GARCH(p,q)$ proces vieme zapísať ako
$$\sigma_{t}^{2}=\omega + \sum_{j=1}^{p}\{\alpha_{j} + \delta_{j}I_{\{e_{t-j}>0\}}\}e_{t-j}^{2} + \sum_{j=1}^{q}  \beta_{j}\sigma_{t-j}^{2},$$
kde $I_{\{e_{t-j}>0\}}$ je spomínaná indikátorová funkcia. 


### TGARCH proces - Treshold
TGARCH, naproti GJR-GARCH procesu, modeluje podmienenú štandardnú odchýlku namiesto podmienenej disperzie. Dynamiku vieme zapísať ako
$$\sigma_{t}= \omega + \sum_{j=1}^{p}\{\alpha_{j} + \delta_{j}I_{\{e_{t-j}>0\}}\}\lvert e_{t-j} \rvert + \sum_{j=1}^{q}  \beta_{j}\sigma_{t-j},$$
kde$I_{\{e_{t-j}>0\}}$ je rovnaká indikátorová funkcia ako v $GJR-GARCH$ procese. Rovnica popisuje štandardný $TGARCH(p,q)$ proces Rovnako je výhodou, že ak modelujeme štandardnú odchýlku, tak nepotrebujeme opäť uvažovať reštrikciu parametrov pretože podmienená variancia $\sigma_{t}^{2}$ je nezáporná už pri konštruovaní.

# Poznámky
* Value at Risk má svoje nedostatky, ako bolo spomenuté na prednáške. Existujú aj iné, lepšie miery rizika ako napríklad Expected Shortfall.

* Pri výpočte VaR nie je nutné aby sa každý deň rekalibroval model. Treba ale potom pri predikovaní volatilty použiť skutočné hodnoty pre $u_{t}$, ktoré získame tak, že použijeme pozorovanú hodnotu pre časový rad v daný deň.